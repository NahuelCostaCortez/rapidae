{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 11:03:11.724338: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath('')\n",
    "sys.path.append(os.path.join(notebook_dir, '..'))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras_core import utils\n",
    "from aepy.data.datasets import load_MNIST\n",
    "from aepy.data.utils import evaluate\n",
    "from aepy.models.base.default_architectures import (Decoder_Conv_MNIST, Decoder_MLP,\n",
    "                                               Encoder_Conv_MNIST, Encoder_MLP)\n",
    "from aepy.models.vae.vae_model import VAE\n",
    "from aepy.pipelines.training import TrainingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 11:03:34 \u001b[32m[INFO]\u001b[0m: train-images-idx3-ubyte.gz already exists.\u001b[0m\n",
      "2023-11-21 11:03:34 \u001b[32m[INFO]\u001b[0m: train-labels-idx1-ubyte.gz already exists.\u001b[0m\n",
      "2023-11-21 11:03:34 \u001b[32m[INFO]\u001b[0m: t10k-images-idx3-ubyte.gz already exists.\u001b[0m\n",
      "2023-11-21 11:03:34 \u001b[32m[INFO]\u001b[0m: t10k-labels-idx1-ubyte.gz already exists.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "x_train, y_train, x_test, y_test = load_MNIST(persistant=True)\n",
    "\n",
    "# Obtaint number of clasess\n",
    "n_classes = len(set(y_train))\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = utils.to_categorical(y_train, n_classes)\n",
    "y_test = utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dict(data=x_train.astype(float), labels=y_train)\n",
    "test_data = dict(data=x_test.astype(float), labels=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 11:03:38 \u001b[32m[INFO]\u001b[0m: Classificator available for the latent space of the autoencoder\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Model creation\n",
    "model = VAE(input_dim=(x_train.shape[0], x_train.shape[1]), latent_dim=10, downstream_task='classification',\n",
    "            encoder=Encoder_Conv_MNIST, decoder=Decoder_Conv_MNIST, layers_conf=[32, 64], n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 11:03:41 \u001b[32m[INFO]\u001b[0m: +++ training_pipeline +++\u001b[0m\n",
      "2023-11-21 11:03:41 \u001b[32m[INFO]\u001b[0m: Creating folder in ../output_dir/training_pipeline_2023-11-21_11-03-41\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 11:04:20.700637: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f78ec015a20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-21 11:04:20.700715: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-11-21 11:04:20.923221: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1700561063.999875   13952 device_compiler.h:187] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-11-21 11:04:24.004595: E external/local_xla/xla/stream_executor/stream_executor_internal.h:181] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: total_loss improved from inf to 11131115536384.00000, saving model to ../output_dir/training_pipeline_2023-11-21_11-03-41/model.weights.h5\n",
      "469/469 - 123s - 262ms/step - clf_loss: 1556.6891 - kl_loss: 11131115536384.0000 - reconstruction_loss: 7217.3125 - total_loss: 11131115536384.0000\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 2: total_loss improved from 11131115536384.00000 to 142058.39062, saving model to ../output_dir/training_pipeline_2023-11-21_11-03-41/model.weights.h5\n",
      "469/469 - 78s - 166ms/step - clf_loss: 2.7070 - kl_loss: 134838.6719 - reconstruction_loss: 7216.9019 - total_loss: 142058.3906\n"
     ]
    }
   ],
   "source": [
    "pipe = TrainingPipeline(name='training_pipeline',\n",
    "                        model=model, num_epochs=2)\n",
    "\n",
    "trained_model = pipe(train_data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step\n",
      "test set results: [\n",
      "\t accuracy_score: 0.2278 \n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2278"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = trained_model.predict(test_data)\n",
    "\n",
    "evaluate(y_true=np.argmax(test_data['labels'], axis=1), \n",
    "         y_hat=np.argmax(y_hat['clf'], axis=1),\n",
    "         sel_metric=accuracy_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aepy-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
