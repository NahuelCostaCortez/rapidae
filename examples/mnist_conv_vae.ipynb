{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "notebook_dir = os.path.abspath('')\n",
    "sys.path.append(os.path.join(notebook_dir, '..'))\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras_core import utils\n",
    "from aepy.data.datasets import load_MNIST\n",
    "from aepy.data.utils import evaluate\n",
    "from aepy.models.base.default_architectures import (Decoder_Conv_MNIST, Decoder_MLP,\n",
    "                                               Encoder_Conv_MNIST, Encoder_MLP)\n",
    "from aepy.models.vae.vae_model import VAE\n",
    "from aepy.pipelines.training import TrainingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n",
      "2.16.0-dev20231103\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 10:31:06 \u001b[32m[INFO]\u001b[0m: train-images-idx3-ubyte.gz already exists.\u001b[0m\n",
      "2023-12-20 10:31:06 \u001b[32m[INFO]\u001b[0m: train-labels-idx1-ubyte.gz already exists.\u001b[0m\n",
      "2023-12-20 10:31:06 \u001b[32m[INFO]\u001b[0m: t10k-images-idx3-ubyte.gz already exists.\u001b[0m\n",
      "2023-12-20 10:31:06 \u001b[32m[INFO]\u001b[0m: t10k-labels-idx1-ubyte.gz already exists.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "x_train, y_train, x_test, y_test = load_MNIST(persistant=True)\n",
    "\n",
    "#x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "#x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255\n",
    "\n",
    "# Obtaint number of clasess\n",
    "n_classes = len(set(y_train))\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = utils.to_categorical(y_train, n_classes)\n",
    "y_test = utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/lucas/experiment/aepy/examples/mnist_conv_vae.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/lucas/experiment/aepy/examples/mnist_conv_vae.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_data \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(data\u001b[39m=\u001b[39mx_train\u001b[39m.\u001b[39;49mastype(\u001b[39mfloat\u001b[39;49m), labels\u001b[39m=\u001b[39my_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucas/experiment/aepy/examples/mnist_conv_vae.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_data \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(data\u001b[39m=\u001b[39mx_test\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m), labels\u001b[39m=\u001b[39my_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucas/experiment/aepy/examples/mnist_conv_vae.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(y_test\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data = dict(data=x_train.astype(float), labels=y_train)\n",
    "test_data = dict(data=x_test.astype(float), labels=y_test)\n",
    "print(y_test.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 10:22:09 \u001b[32m[INFO]\u001b[0m: Classificator available for the latent space of the autoencoder\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Model creation\n",
    "model = VAE(input_dim=(x_train.shape[1], x_train.shape[2]), latent_dim=10, downstream_task='classification',\n",
    "            encoder=Encoder_Conv_MNIST, decoder=Decoder_Conv_MNIST, layers_conf=[32, 64], n_classes=n_classes,\n",
    "            weight_vae=0.25, weight_clf=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 10:22:09 \u001b[32m[INFO]\u001b[0m: +++ training_pipeline +++\u001b[0m\n",
      "2023-12-20 10:22:09 \u001b[32m[INFO]\u001b[0m: Creating folder in ../output_dir/training_pipeline_2023-12-20_10-22-09\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 10:22:10.360514: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: loss improved from inf to 29386.04492, saving model to ../output_dir/training_pipeline_2023-12-20_10-22-09/model.weights.h5\n",
      "469/469 - 137s - 292ms/step - clf_loss: 2.5943 - kl_loss: 110119.3906 - loss: 29386.0449 - reconstruction_loss: 7217.3179\n",
      "Epoch 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 10:24:27.443720: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: loss improved from 29386.04492 to 1835.87000, saving model to ../output_dir/training_pipeline_2023-12-20_10-22-09/model.weights.h5\n",
      "469/469 - 132s - 281ms/step - clf_loss: 1.0566 - kl_loss: 41.7166 - loss: 1835.8700 - reconstruction_loss: 7217.2324\n",
      "Epoch 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 10:26:38.888980: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: loss improved from 1835.87000 to 1826.79236, saving model to ../output_dir/training_pipeline_2023-12-20_10-22-09/model.weights.h5\n",
      "469/469 - 131s - 278ms/step - clf_loss: 0.6774 - kl_loss: 35.9561 - loss: 1826.7924 - reconstruction_loss: 7217.0190\n",
      "Epoch 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 10:28:49.434239: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/lucas/experiment/aepy/examples/mnist_conv_vae.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucas/experiment/aepy/examples/mnist_conv_vae.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pipe \u001b[39m=\u001b[39m TrainingPipeline(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtraining_pipeline\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucas/experiment/aepy/examples/mnist_conv_vae.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                         model\u001b[39m=\u001b[39mmodel, num_epochs\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/lucas/experiment/aepy/examples/mnist_conv_vae.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m trained_model \u001b[39m=\u001b[39m pipe(x\u001b[39m=\u001b[39;49mx_train\u001b[39m.\u001b[39;49mastype(\u001b[39mfloat\u001b[39;49m), y\u001b[39m=\u001b[39;49my_train)\n",
      "File \u001b[0;32m~/experiment/aepy/examples/../aepy/pipelines/training.py:94\u001b[0m, in \u001b[0;36mTrainingPipeline.__call__\u001b[0;34m(self, x, y, x_eval, y_eval, callbacks, save_model)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer, run_eagerly\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m x_eval \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     95\u001b[0m                 x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m     96\u001b[0m                 y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m     97\u001b[0m                 shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     98\u001b[0m                 epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_epochs,\n\u001b[1;32m     99\u001b[0m                 batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[1;32m    100\u001b[0m                 callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    101\u001b[0m                 verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    102\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(\n\u001b[1;32m    104\u001b[0m                 x\u001b[39m=\u001b[39mx,\n\u001b[1;32m    105\u001b[0m                 y\u001b[39m=\u001b[39my,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m    111\u001b[0m                 verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/keras_core/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/keras_core/src/backend/tensorflow/trainer.py:322\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39mfor\u001b[39;00m step, iterator \u001b[39min\u001b[39;00m epoch_iterator\u001b[39m.\u001b[39menumerate_epoch():\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 322\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m    323\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    324\u001b[0m         step, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    325\u001b[0m     )\n\u001b[1;32m    326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/keras_core/src/backend/tensorflow/trainer.py:117\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m--> 117\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    118\u001b[0m     one_step_on_data, args\u001b[39m=\u001b[39;49m(data,)\n\u001b[1;32m    119\u001b[0m )\n\u001b[1;32m    120\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    121\u001b[0m     outputs,\n\u001b[1;32m    122\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[1;32m    123\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m    124\u001b[0m )\n\u001b[1;32m    125\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:1681\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   1677\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   1680\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1681\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3271\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   3270\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 3271\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4069\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4067\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4068\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m-> 4069\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/keras_core/src/backend/tensorflow/trainer.py:105\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@tf\u001b[39m\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mdo_not_convert\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mone_step_on_data\u001b[39m(data):\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(data)\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/keras_core/src/backend/tensorflow/trainer.py:59\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(x)\n\u001b[0;32m---> 59\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(\n\u001b[1;32m     60\u001b[0m     x\u001b[39m=\u001b[39;49mx, y\u001b[39m=\u001b[39;49my, y_pred\u001b[39m=\u001b[39;49my_pred, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[1;32m     61\u001b[0m )\n\u001b[1;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss_tracker\u001b[39m.\u001b[39mupdate_state(loss)\n\u001b[1;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/experiment/aepy/examples/../aepy/models/vae/vae_model.py:101\u001b[0m, in \u001b[0;36mVAE.compute_loss\u001b[0;34m(self, x, y, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m     98\u001b[0m kl_loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m y_pred[\u001b[39m'\u001b[39m\u001b[39mz_log_var\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m\n\u001b[1;32m     99\u001b[0m                   keras\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39msquare(y_pred[\u001b[39m'\u001b[39m\u001b[39mz_mean\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m-\u001b[39m keras\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mexp(y_pred[\u001b[39m'\u001b[39m\u001b[39mz_log_var\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m    100\u001b[0m kl_loss \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mmean(keras\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39msum(kl_loss, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m--> 101\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkl_loss_tracker\u001b[39m.\u001b[39;49mupdate_state(kl_loss)\n\u001b[1;32m    103\u001b[0m \u001b[39m# Reconstruction loss\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m# TODO: Check masking issues\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/keras_core/src/metrics/reduction_metrics.py:144\u001b[0m, in \u001b[0;36mMean.update_state\u001b[0;34m(self, values, sample_weight)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     num_samples \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39msum(sample_weight)\n\u001b[0;32m--> 144\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount\u001b[39m.\u001b[39massign(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcount \u001b[39m+\u001b[39m ops\u001b[39m.\u001b[39;49mcast(num_samples, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype))\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/keras_core/src/ops/core.py:460\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(x, dtype)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m any_symbolic_tensors((x,)):\n\u001b[1;32m    459\u001b[0m     \u001b[39mreturn\u001b[39;00m Cast(dtype\u001b[39m=\u001b[39mdtype)(x)\n\u001b[0;32m--> 460\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcore\u001b[39m.\u001b[39;49mcast(x, dtype)\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/keras_core/src/backend/tensorflow/core.py:127\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(x, dtype)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcast\u001b[39m(x, dtype):\n\u001b[1;32m    126\u001b[0m     dtype \u001b[39m=\u001b[39m standardize_dtype(dtype)\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mcast(x, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:140\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror_handler\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    139\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_traceback_filtering_enabled():\n\u001b[1;32m    141\u001b[0m       \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    142\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mNameError\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[39m# In some very rare cases,\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[39m# `is_traceback_filtering_enabled` (from the outer scope) may not be\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[39m# accessible from inside this function\u001b[39;00m\n",
      "File \u001b[0;32m~/python_envs/aepy-test/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:32\u001b[0m, in \u001b[0;36mis_traceback_filtering_enabled\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m _ENABLE_TRACEBACK_FILTERING \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mlocal()\n\u001b[1;32m     27\u001b[0m _EXCLUDED_PATHS \u001b[39m=\u001b[39m (\n\u001b[1;32m     28\u001b[0m     os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m__file__\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m)),\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdebugging.is_traceback_filtering_enabled\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_traceback_filtering_enabled\u001b[39m():\n\u001b[1;32m     34\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Check whether traceback filtering is currently enabled.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[39m  See also `tf.debugging.enable_traceback_filtering()` and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m    was called).\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m   value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(_ENABLE_TRACEBACK_FILTERING, \u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipe = TrainingPipeline(name='training_pipeline',\n",
    "                        model=model, num_epochs=6, batch_size=128)\n",
    "\n",
    "trained_model = pipe(x=x_train.astype(float), y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filepath='../output_dir/training_pipeline_2023-11-25_00-50-30/model.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_clusters(vae,  must be equal, but ar\n",
    "    # Display a 2D plot of the digit classes in the latent space\n",
    "    _, _, z = vae.predict(data)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z[:, 0], z[:, 1], c=labels)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()\n",
    "    if include_flow:\n",
    "      z = vae.flow.inverse(z)\n",
    "      plt.figure(figsize=(12, 10))\n",
    "      plt.scatter(z[:, 0], z[:, 1], c=labels)\n",
    "      plt.colorbar()\n",
    "      plt.xlabel(\"z[0]\")\n",
    "      plt.ylabel(\"z[1]\")\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label_clusters(model, train_data, y_train)\n",
    "plot_label_clusters(model, test_data, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#y_train_predict = model.predict(train_data)\n",
    "y_test_predict =  model.predict(test_data)\n",
    "\n",
    "print(np.argmax(y_test_predict['clf'], axis=1))\n",
    "print(np.argmax(y_test, axis=1))\n",
    "\n",
    "target_names = ['number 0', 'number 1', 'number 2', 'number 3', 'number 4', 'number 5', 'number 6', 'number 7', 'number 8', 'number 9']\n",
    "\n",
    "#classification_report(y_train, np.argmax(y_train_predict['clf'], axis=1), target_names=target_names)\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_test_predict['clf'], axis=1), target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = trained_model.predict(test_data)\n",
    "\n",
    "evaluate(y_true=np.argmax(test_data['labels'], axis=1), \n",
    "         y_hat=np.argmax(y_hat['clf'], axis=1),\n",
    "         sel_metric=accuracy_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aepy-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
