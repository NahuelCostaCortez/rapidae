{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:16:20.940654: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath('')\n",
    "sys.path.append(os.path.join(notebook_dir, '..'))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras_core import utils\n",
    "from aepy.data.datasets import load_MNIST\n",
    "from aepy.data.utils import evaluate\n",
    "from aepy.models.base.default_architectures import (Decoder_Conv_MNIST, Decoder_MLP,\n",
    "                                               Encoder_Conv_MNIST, Encoder_MLP)\n",
    "from aepy.models.vae.vae_model import VAE\n",
    "from aepy.pipelines.training import TrainingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:16:22 \u001b[32m[INFO]\u001b[0m: train-images-idx3-ubyte.gz already exists.\u001b[0m\n",
      "2023-11-22 20:16:22 \u001b[32m[INFO]\u001b[0m: train-labels-idx1-ubyte.gz already exists.\u001b[0m\n",
      "2023-11-22 20:16:22 \u001b[32m[INFO]\u001b[0m: t10k-images-idx3-ubyte.gz already exists.\u001b[0m\n",
      "2023-11-22 20:16:22 \u001b[32m[INFO]\u001b[0m: t10k-labels-idx1-ubyte.gz already exists.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "x_train, y_train, x_test, y_test = load_MNIST(persistant=True)\n",
    "\n",
    "# Obtaint number of clasess\n",
    "n_classes = len(set(y_train))\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = utils.to_categorical(y_train, n_classes)\n",
    "y_test = utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dict(data=x_train.astype(float), labels=y_train)\n",
    "test_data = dict(data=x_test.astype(float), labels=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:16:22 \u001b[32m[INFO]\u001b[0m: Classificator available for the latent space of the autoencoder\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Model creation\n",
    "model = VAE(input_dim=(x_train.shape[0], x_train.shape[1]), latent_dim=10, downstream_task='classification',\n",
    "            encoder=Encoder_Conv_MNIST, decoder=Decoder_Conv_MNIST, layers_conf=[32, 64], n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:16:22 \u001b[32m[INFO]\u001b[0m: +++ training_pipeline +++\u001b[0m\n",
      "2023-11-22 20:16:22 \u001b[32m[INFO]\u001b[0m: Creating folder in ../output_dir/training_pipeline_2023-11-22_20-16-22\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "[<tf.Tensor 'gradient_tape/encoder_1/z_mean_1/MatMul_1:0' shape=(16, 10) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/z_mean_1/add/Reshape:0' shape=(10,) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/z_log_var_1/MatMul_1:0' shape=(16, 10) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/z_log_var_1/add/Reshape:0' shape=(10,) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/conv2d_1/convolution/Conv2DBackpropFilter:0' shape=(3, 3, 1, 32) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/conv2d_1/Reshape:0' shape=(32,) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/conv2d_1_2/convolution/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/conv2d_1_2/Reshape:0' shape=(64,) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/dense_1/MatMul_1:0' shape=(3136, 16) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/dense_1/add/Reshape:0' shape=(16,) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/dense_1_1/MatMul_1:0' shape=(10, 3136) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/dense_1_1/add/Reshape:0' shape=(3136,) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/conv2d_transpose_1/conv_transpose/Conv2DBackpropFilter:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/conv2d_transpose_1/Reshape:0' shape=(64,) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/conv2d_transpose_1_2/conv_transpose/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/conv2d_transpose_1_2/Reshape:0' shape=(32,) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/conv2d_transpose_2_1/conv_transpose/Conv2DBackpropFilter:0' shape=(3, 3, 1, 32) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/conv2d_transpose_2_1/Reshape:0' shape=(1,) dtype=float32>, <tf.Tensor 'gradient_tape/classifier_1/dense_2_1/MatMul_1:0' shape=(10, 200) dtype=float32>, <tf.Tensor 'gradient_tape/classifier_1/dense_2_1/add/Reshape:0' shape=(200,) dtype=float32>, <tf.Tensor 'gradient_tape/classifier_1/class_output_1/MatMul_1:0' shape=(200, 10) dtype=float32>, <tf.Tensor 'gradient_tape/classifier_1/class_output_1/add/Reshape:0' shape=(10,) dtype=float32>]\n",
      "[<tf.Tensor 'gradient_tape/encoder_1/z_mean_1/MatMul_1:0' shape=(16, 10) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/z_mean_1/add/Reshape:0' shape=(10,) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/z_log_var_1/MatMul_1:0' shape=(16, 10) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/z_log_var_1/add/Reshape:0' shape=(10,) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/conv2d_1/convolution/Conv2DBackpropFilter:0' shape=(3, 3, 1, 32) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/conv2d_1/Reshape:0' shape=(32,) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/conv2d_1_2/convolution/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/conv2d_1_2/Reshape:0' shape=(64,) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/dense_1/MatMul_1:0' shape=(3136, 16) dtype=float32>, <tf.Tensor 'gradient_tape/encoder_1/dense_1/add/Reshape:0' shape=(16,) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/dense_1_1/MatMul_1:0' shape=(10, 3136) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/dense_1_1/add/Reshape:0' shape=(3136,) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/conv2d_transpose_1/conv_transpose/Conv2DBackpropFilter:0' shape=(3, 3, 64, 64) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/conv2d_transpose_1/Reshape:0' shape=(64,) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/conv2d_transpose_1_2/conv_transpose/Conv2DBackpropFilter:0' shape=(3, 3, 32, 64) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/conv2d_transpose_1_2/Reshape:0' shape=(32,) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/conv2d_transpose_2_1/conv_transpose/Conv2DBackpropFilter:0' shape=(3, 3, 1, 32) dtype=float32>, <tf.Tensor 'gradient_tape/decoder_1/conv2d_transpose_2_1/Reshape:0' shape=(1,) dtype=float32>, <tf.Tensor 'gradient_tape/classifier_1/dense_2_1/MatMul_1:0' shape=(10, 200) dtype=float32>, <tf.Tensor 'gradient_tape/classifier_1/dense_2_1/add/Reshape:0' shape=(200,) dtype=float32>, <tf.Tensor 'gradient_tape/classifier_1/class_output_1/MatMul_1:0' shape=(200, 10) dtype=float32>, <tf.Tensor 'gradient_tape/classifier_1/class_output_1/add/Reshape:0' shape=(10,) dtype=float32>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 20:16:35.203633: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fc84c016d20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-22 20:16:35.203656: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-11-22 20:16:35.272254: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1700680596.194943   11205 device_compiler.h:187] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-11-22 20:16:36.196696: E external/local_xla/xla/stream_executor/stream_executor_internal.h:181] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: total_loss improved from inf to 84909208.00000, saving model to ../output_dir/training_pipeline_2023-11-22_20-16-22/model.weights.h5\n",
      "469/469 - 49s - 104ms/step - clf_loss: 24.7585 - kl_loss: 84901288.0000 - reconstruction_loss: 7217.4004 - total_loss: 84909208.0000\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/lucaspc/aepy-project/aepy/examples/mnist_conv_vae.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucaspc/aepy-project/aepy/examples/mnist_conv_vae.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pipe \u001b[39m=\u001b[39m TrainingPipeline(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtraining_pipeline\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucaspc/aepy-project/aepy/examples/mnist_conv_vae.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                         model\u001b[39m=\u001b[39mmodel, num_epochs\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/lucaspc/aepy-project/aepy/examples/mnist_conv_vae.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m trained_model \u001b[39m=\u001b[39m pipe(train_data\u001b[39m=\u001b[39;49mtrain_data)\n",
      "File \u001b[0;32m~/aepy-project/aepy/examples/../aepy/pipelines/training.py:96\u001b[0m, in \u001b[0;36mTrainingPipeline.__call__\u001b[0;34m(self, train_data, eval_data, callbacks, save_model)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m# compile and fit the model\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer)\n\u001b[0;32m---> 96\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(train_data,\n\u001b[1;32m     97\u001b[0m                validation_data\u001b[39m=\u001b[39;49meval_data,\n\u001b[1;32m     98\u001b[0m                shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     99\u001b[0m                epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_epochs,\n\u001b[1;32m    100\u001b[0m                batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[1;32m    101\u001b[0m                callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    102\u001b[0m                verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    104\u001b[0m \u001b[39m# restore the best model\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mload_weights(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_dir, \u001b[39m'\u001b[39m\u001b[39mmodel.weights.h5\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/venvs/keras_core/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/venvs/keras_core/lib/python3.11/site-packages/keras_core/src/backend/tensorflow/trainer.py:324\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    321\u001b[0m callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m    322\u001b[0m logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    323\u001b[0m callbacks\u001b[39m.\u001b[39mon_train_batch_end(\n\u001b[0;32m--> 324\u001b[0m     step, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pythonify_logs(logs)\n\u001b[1;32m    325\u001b[0m )\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m    327\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/keras_core/lib/python3.11/site-packages/keras_core/src/trainers/trainer.py:831\u001b[0m, in \u001b[0;36mTrainer._pythonify_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    825\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    826\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected `validation_freq` to be a list or int. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    827\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived: validation_freq=\u001b[39m\u001b[39m{\u001b[39;00mvalidation_freq\u001b[39m}\u001b[39;00m\u001b[39m of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    828\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(validation_freq)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    829\u001b[0m         )\n\u001b[0;32m--> 831\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pythonify_logs\u001b[39m(\u001b[39mself\u001b[39m, logs):\n\u001b[1;32m    832\u001b[0m     result \u001b[39m=\u001b[39m {}\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(logs\u001b[39m.\u001b[39mitems()):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipe = TrainingPipeline(name='training_pipeline',\n",
    "                        model=model, num_epochs=2)\n",
    "\n",
    "trained_model = pipe(train_data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = trained_model.predict(test_data)\n",
    "\n",
    "evaluate(y_true=np.argmax(test_data['labels'], axis=1), \n",
    "         y_hat=np.argmax(y_hat['clf'], axis=1),\n",
    "         sel_metric=accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tensor = tf.range(10)\n",
    "tf.print(tensor, output_stream=sys.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aepy-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
