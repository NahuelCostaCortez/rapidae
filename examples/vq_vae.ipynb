{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fist install the library\n",
    "\n",
    "#%pip install aepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 13:46:19.548906: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath('')\n",
    "sys.path.append(os.path.join(notebook_dir, '..'))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras_core import utils\n",
    "\n",
    "from aepy.data.datasets import load_MNIST\n",
    "from aepy.data.utils import evaluate, display_diff, add_noise\n",
    "from aepy.models.vq_vae.vq_vae_model import VQ_VAE\n",
    "from aepy.models.base.default_architectures import Encoder_Conv_VQ_MNIST, Decoder_Conv_VQ_MNIST\n",
    "from aepy.pipelines.training import TrainingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 13:46:23 \u001b[32m[INFO]\u001b[0m: train-images-idx3-ubyte.gz already exists.\u001b[0m\n",
      "2023-12-07 13:46:23 \u001b[32m[INFO]\u001b[0m: train-labels-idx1-ubyte.gz already exists.\u001b[0m\n",
      "2023-12-07 13:46:23 \u001b[32m[INFO]\u001b[0m: t10k-images-idx3-ubyte.gz already exists.\u001b[0m\n",
      "2023-12-07 13:46:23 \u001b[32m[INFO]\u001b[0m: t10k-labels-idx1-ubyte.gz already exists.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "x_train, y_train, x_test, y_test = load_MNIST(persistant=True)\n",
    "\n",
    "# Obtaint number of clasess\n",
    "n_classes = len(set(y_train))\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = utils.to_categorical(y_train, n_classes)\n",
    "y_test = utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dict(data=x_train.astype(float), labels=x_train)\n",
    "test_data = dict(data=x_test.astype(float), labels=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "2\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Model creation\n",
    "model = VQ_VAE(input_dim=(x_train.shape[1], x_train.shape[2]), \n",
    "            latent_dim=2, encoder=Encoder_Conv_VQ_MNIST, decoder=Decoder_Conv_VQ_MNIST, layers_conf=[32, 64])\n",
    "\n",
    "model.jit_compile = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 13:46:24 \u001b[32m[INFO]\u001b[0m: +++ training_pipeline +++\u001b[0m\n",
      "2023-12-07 13:46:24 \u001b[32m[INFO]\u001b[0m: Creating folder in ../output_dir/training_pipeline_2023-12-07_13-46-24\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/python_envs/aepy-test/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:371: UserWarning: `build()` was called on layer 'encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  return py_builtins.overload_of(f)(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 7, 7, 2)\n",
      "Tensor(\"vector_quantizer_1/Shape:0\", shape=(4,), dtype=int32)\n",
      "(6272, 2)\n",
      "Quantizarion process\n",
      "(6272,)\n",
      "Tensor(\"vector_quantizer_1/one_hot:0\", shape=(6272, 128), dtype=float32)\n",
      "Tensor(\"vector_quantizer_1/MatMul_1:0\", shape=(6272, 2), dtype=float32)\n",
      "Pre-reshape\n",
      "Post-reshape\n",
      "(128, 7, 7, 2)\n",
      "Tensor(\"vector_quantizer_1/Mean:0\", shape=(), dtype=float32)\n",
      "Tensor(\"vector_quantizer_1/Mean_1:0\", shape=(), dtype=float32)\n",
      "Post-add_loss\n",
      "Last step\n",
      "(128, 7, 7, 2)\n",
      "[]\n",
      "(128, 7, 7, 2)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/Shape:0\", shape=(4,), dtype=int32)\n",
      "(6272, 2)\n",
      "Quantizarion process\n",
      "(6272,)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/one_hot:0\", shape=(6272, 128), dtype=float32)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/MatMul_1:0\", shape=(6272, 2), dtype=float32)\n",
      "Pre-reshape\n",
      "Post-reshape\n",
      "(128, 7, 7, 2)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/Mean:0\", shape=(), dtype=float32)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/Mean_1:0\", shape=(), dtype=float32)\n",
      "Post-add_loss\n",
      "Last step\n",
      "(128, 7, 7, 2)\n",
      "[<tf.Tensor 'vq_vae_1/vector_quantizer_1/add_1:0' shape=() dtype=float32>]\n",
      "(128, 7, 7, 2)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/Shape:0\", shape=(4,), dtype=int32)\n",
      "(6272, 2)\n",
      "Quantizarion process\n",
      "(6272,)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/one_hot:0\", shape=(6272, 128), dtype=float32)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/MatMul_1:0\", shape=(6272, 2), dtype=float32)\n",
      "Pre-reshape\n",
      "Post-reshape\n",
      "(128, 7, 7, 2)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/Mean:0\", shape=(), dtype=float32)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/Mean_1:0\", shape=(), dtype=float32)\n",
      "Post-add_loss\n",
      "Last step\n",
      "(128, 7, 7, 2)\n",
      "[<tf.Tensor 'vq_vae_1/vector_quantizer_1/add_1:0' shape=() dtype=float32>]\n",
      "(96, 7, 7, 2)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/Shape:0\", shape=(4,), dtype=int32)\n",
      "(4704, 2)\n",
      "Quantizarion process\n",
      "(4704,)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/one_hot:0\", shape=(4704, 128), dtype=float32)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/MatMul_1:0\", shape=(4704, 2), dtype=float32)\n",
      "Pre-reshape\n",
      "Post-reshape\n",
      "(96, 7, 7, 2)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/Mean:0\", shape=(), dtype=float32)\n",
      "Tensor(\"vq_vae_1/vector_quantizer_1/Mean_1:0\", shape=(), dtype=float32)\n",
      "Post-add_loss\n",
      "Last step\n",
      "(96, 7, 7, 2)\n",
      "[<tf.Tensor 'vq_vae_1/vector_quantizer_1/add_1:0' shape=() dtype=float32>]\n",
      "\n",
      "Epoch 1: total_loss improved from inf to 1596.54370, saving model to ../output_dir/training_pipeline_2023-12-07_13-46-24/model.weights.h5\n",
      "469/469 - 63s - 134ms/step - reconstruction_loss: 1056.9034 - total_loss: 1596.5437 - vq_loss: 539.6409\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: total_loss improved from 1596.54370 to 581.04639, saving model to ../output_dir/training_pipeline_2023-12-07_13-46-24/model.weights.h5\n",
      "469/469 - 26s - 56ms/step - reconstruction_loss: 413.9556 - total_loss: 581.0464 - vq_loss: 167.0909\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: total_loss improved from 581.04639 to 470.88373, saving model to ../output_dir/training_pipeline_2023-12-07_13-46-24/model.weights.h5\n",
      "469/469 - 26s - 56ms/step - reconstruction_loss: 355.4710 - total_loss: 470.8837 - vq_loss: 115.4127\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: total_loss improved from 470.88373 to 417.77240, saving model to ../output_dir/training_pipeline_2023-12-07_13-46-24/model.weights.h5\n",
      "469/469 - 26s - 56ms/step - reconstruction_loss: 326.3244 - total_loss: 417.7724 - vq_loss: 91.4479\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: total_loss improved from 417.77240 to 384.31381, saving model to ../output_dir/training_pipeline_2023-12-07_13-46-24/model.weights.h5\n",
      "469/469 - 27s - 58ms/step - reconstruction_loss: 308.1028 - total_loss: 384.3138 - vq_loss: 76.2108\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: total_loss improved from 384.31381 to 360.33002, saving model to ../output_dir/training_pipeline_2023-12-07_13-46-24/model.weights.h5\n",
      "469/469 - 27s - 58ms/step - reconstruction_loss: 294.6744 - total_loss: 360.3300 - vq_loss: 65.6553\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 7: total_loss improved from 360.33002 to 342.51147, saving model to ../output_dir/training_pipeline_2023-12-07_13-46-24/model.weights.h5\n",
      "469/469 - 27s - 57ms/step - reconstruction_loss: 284.8210 - total_loss: 342.5115 - vq_loss: 57.6904\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 8: total_loss improved from 342.51147 to 328.34409, saving model to ../output_dir/training_pipeline_2023-12-07_13-46-24/model.weights.h5\n",
      "469/469 - 26s - 55ms/step - reconstruction_loss: 276.6515 - total_loss: 328.3441 - vq_loss: 51.6927\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 9: total_loss improved from 328.34409 to 316.51462, saving model to ../output_dir/training_pipeline_2023-12-07_13-46-24/model.weights.h5\n",
      "469/469 - 26s - 55ms/step - reconstruction_loss: 269.6674 - total_loss: 316.5146 - vq_loss: 46.8470\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 10: total_loss improved from 316.51462 to 306.63947, saving model to ../output_dir/training_pipeline_2023-12-07_13-46-24/model.weights.h5\n",
      "469/469 - 26s - 56ms/step - reconstruction_loss: 263.7961 - total_loss: 306.6395 - vq_loss: 42.8433\n"
     ]
    }
   ],
   "source": [
    "pipe = TrainingPipeline(name='training_pipeline',\n",
    "                        model=model, num_epochs=10)\n",
    "\n",
    "trained_model = pipe(train_data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aepy-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
