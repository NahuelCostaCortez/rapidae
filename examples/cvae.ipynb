{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder and decoder in addition to the input data are provided with an embedding vector that represents a condition. Thus, the encoder does not need to represent the condition in the latent space since the decoder will also get this information as an extra input.\n",
    "\n",
    "In this example we will use the MNIST dataset: the encoder can regress out the condition (specific digits) and learn the handwriting style as a latent representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library\n",
    "\n",
    "!pip install rapidae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath('') # get the current notebook directory\n",
    "sys.path.append(os.path.join(notebook_dir, 'rapidae', 'src')) # add src folder to path to import modules\n",
    "                                                        # '..', 'src' if you are in the 'examples' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidae.data import load_dataset\n",
    "from rapidae.models import CVAE\n",
    "from rapidae.models.base import VAE_Encoder_MLP, VAE_Decoder_MLP\n",
    "from rapidae.pipelines import TrainingPipeline\n",
    "from rapidae.evaluate import plot_latent_space, plot_reconstructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 18:10:32 \u001b[32m[INFO]\u001b[0m: Downloading data...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "data = load_dataset(\"MNIST\")\n",
    "\n",
    "# normalize data\n",
    "x_train = data[\"x_train\"].reshape(data[\"x_train\"].shape[0], -1) / 255\n",
    "x_test = data[\"x_test\"].reshape(data[\"x_test\"].shape[0], -1) / 255\n",
    "y_train = data[\"y_train\"]\n",
    "y_test = data[\"y_test\"]\n",
    "\n",
    "print(\"Data shape:\", x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only images of 0–7 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "idx_07 = np.where((data[\"y_train\"] != 8) & (data[\"y_train\"] == 9))[0]\n",
    "x_train_07 = x_train[idx_07]\n",
    "y_train_07 = y_train[idx_07]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 18:12:44 \u001b[32m[INFO]\u001b[0m: Using provided encoder\u001b[0m\n",
      "2024-05-06 18:12:44 \u001b[32m[INFO]\u001b[0m: Using provided decoder\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input_dim = x_train.shape[1:]\n",
    "# Model creation\n",
    "model = CVAE(input_dim=input_dim, \n",
    "            latent_dim=2,\n",
    "            encoder=VAE_Encoder_MLP(input_dim=input_dim, latent_dim=2), \n",
    "            decoder=VAE_Decoder_MLP(input_dim=input_dim, latent_dim=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 18:12:47 \u001b[32m[INFO]\u001b[0m: +++ CVAE_MNIST +++\u001b[0m\n",
      "2024-05-06 18:12:47 \u001b[32m[INFO]\u001b[0m: Creating folder in ./output_dir/CVAE_MNIST_2024-05-06_18-12\u001b[0m\n",
      "2024-05-06 18:12:47 \u001b[32m[INFO]\u001b[0m: \n",
      "TRAINING STARTED\n",
      "\tBackend: tensorflow\n",
      "\tEager mode: True\n",
      "\tValidation data available: False\n",
      "\tCallbacks set: ['EarlyStopping', 'ModelCheckpoint'] \n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 18:12:47.145814: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/layers/layer.py:1265: UserWarning: Layer 'cvae_1' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''Exception encountered when calling VAE_Decoder_MLP.call().\n",
      "\n",
      "\u001b[1mInvalid dtype: tuple\u001b[0m\n",
      "\n",
      "Arguments received by VAE_Decoder_MLP.call():\n",
      "  • z=tf.Tensor(shape=(128, 4), dtype=float32)''\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/layers/layer.py:360: UserWarning: `build()` was called on layer 'cvae_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling VAE_Decoder_MLP.call().\n\n\u001b[1mInvalid dtype: tuple\u001b[0m\n\nArguments received by VAE_Decoder_MLP.call():\n  • z=tf.Tensor(shape=(128, 4), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m pipe \u001b[38;5;241m=\u001b[39m TrainingPipeline(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCVAE_MNIST\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      2\u001b[0m                         learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m      3\u001b[0m                         model\u001b[38;5;241m=\u001b[39mmodel, \n\u001b[1;32m      4\u001b[0m                         num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, \n\u001b[1;32m      5\u001b[0m                         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      6\u001b[0m                         run_eagerly\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,)\n\u001b[0;32m----> 8\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rapidae/src/rapidae/pipelines/training.py:188\u001b[0m, in \u001b[0;36mTrainingPipeline.__call__\u001b[0;34m(self, x, y, x_val, y_val)\u001b[0m\n\u001b[1;32m    176\u001b[0m validation_data \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    177\u001b[0m     (x_val, y_val) \u001b[38;5;28;01mif\u001b[39;00m x_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m y_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    178\u001b[0m )\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_info(\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTRAINING STARTED\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mBackend: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mEager mode: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mValidation data available: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mCallbacks set: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    181\u001b[0m         backend(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m     )\n\u001b[1;32m    186\u001b[0m )\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Restore the best model\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# check if file exists\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/rapidae/src/rapidae/models/cvae/cvae_model.py:58\u001b[0m, in \u001b[0;36mCVAE.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# decoder\u001b[39;00m\n\u001b[1;32m     57\u001b[0m decoder_inputs \u001b[38;5;241m=\u001b[39m Concatenate(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)([z, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcondition_embedding(y)])\n\u001b[0;32m---> 58\u001b[0m x_recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m: z,\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m: z_mean,\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz_log_var\u001b[39m\u001b[38;5;124m\"\u001b[39m: z_log_var,\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_recon\u001b[39m\u001b[38;5;124m\"\u001b[39m: x_recon,\n\u001b[1;32m     65\u001b[0m }\n",
      "File \u001b[0;32m~/rapidae/src/rapidae/models/base/default_architectures.py:190\u001b[0m, in \u001b[0;36mVAE_Decoder_MLP.call\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    189\u001b[0m     z \u001b[38;5;241m=\u001b[39m layer(z)\n\u001b[0;32m--> 190\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense_recons\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling VAE_Decoder_MLP.call().\n\n\u001b[1mInvalid dtype: tuple\u001b[0m\n\nArguments received by VAE_Decoder_MLP.call():\n  • z=tf.Tensor(shape=(128, 4), dtype=float32)"
     ]
    }
   ],
   "source": [
    "pipe = TrainingPipeline(name='CVAE_MNIST', \n",
    "                        learning_rate=0.001,\n",
    "                        model=model, \n",
    "                        num_epochs=30, \n",
    "                        batch_size=128,\n",
    "                        run_eagerly=True,)\n",
    "\n",
    "trained_model = pipe(x=(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente z es una tupla, averiguar por qué"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
