{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<a href=\"https://colab.research.google.com/github/NahuelCostaCortez/rapidae/blob/main/examples/vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# MLP VAE with MNIST dataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A Variational Autoencoder (VAE) is a type of generative model that combines the principles of autoencoders and probabilistic modeling. VAEs are designed to learn a probabilistic mapping between high-dimensional input data and a lower-dimensional latent space, capturing meaningful representations of the input data. In a VAE, the encoder network maps input data to a distribution in the latent space, typically modeled as a Gaussian distribution. The decoder network then samples from this distribution to reconstruct the input data. Importantly, VAEs introduce a probabilistic element by enforcing that the latent space follows a specific probability distribution, usually a multivariate Gaussian. During training, VAEs maximize a variational lower bound on the log-likelihood of the data. This involves minimizing the reconstruction error, ensuring that the generated samples resemble the input data, and regularizing the distribution of the latent space to follow the desired probability distribution.\n",
                "\n",
                "VAEs have applications in generative tasks, such as image and text generation, and are valued for their ability to generate diverse and realistic samples while providing a structured latent space that allows for interpolation and manipulation of data representations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install the library\n",
                "\n",
                "!pip install rapidae"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-01-11 20:58:40.405535: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "2024-01-11 20:58:40.405565: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "2024-01-11 20:58:40.406261: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "2024-01-11 20:58:40.411587: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
                        "2024-01-11 20:58:41.137024: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
                    ]
                }
            ],
            "source": [
                "from keras import utils\n",
                "from rapidae.data import load_MNIST\n",
                "from rapidae.models import VAE\n",
                "from rapidae.models.base import Encoder_MLP, Decoder_MLP\n",
                "from rapidae.pipelines import TrainingPipeline\n",
                "from rapidae.evaluate import plot_reconstructions"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data\n",
                "\n",
                "Download and preprocess the dataset. In this example, the selected dataset is the well-known MNIST composed of handwritten digit images.\n",
                "\n",
                "Train and test data are normalized and flatten (since Dense layers are going to be used)\n",
                "We also need to convert the labels into one-hot encoding."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-01-11 20:58:41 \u001b[32m[INFO]\u001b[0m: train-images-idx3-ubyte.gz already exists.\u001b[0m\n",
                        "2024-01-11 20:58:41 \u001b[32m[INFO]\u001b[0m: train-labels-idx1-ubyte.gz already exists.\u001b[0m\n",
                        "2024-01-11 20:58:41 \u001b[32m[INFO]\u001b[0m: t10k-images-idx3-ubyte.gz already exists.\u001b[0m\n",
                        "2024-01-11 20:58:41 \u001b[32m[INFO]\u001b[0m: t10k-labels-idx1-ubyte.gz already exists.\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "# Load MNIST dataset\n",
                "x_train, y_train, x_test, y_test = load_MNIST()\n",
                "\n",
                "x_train = x_train.reshape(x_train.shape[0], -1).astype(\"float32\") / 255\n",
                "x_test = x_test.reshape(x_test.shape[0], -1).astype(\"float32\") / 255\n",
                "\n",
                "# Obtain number of clasess\n",
                "n_classes = len(set(y_train))\n",
                "\n",
                "# Convert labels to categorical\n",
                "y_train = utils.to_categorical(y_train, n_classes)\n",
                "y_test = utils.to_categorical(y_test, n_classes)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Model\n",
                "\n",
                "In this example we are using a vanilla MLP variational autoencoder. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-01-11 20:58:41 \u001b[32m[INFO]\u001b[0m: No specific dowstream task has been selected\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "# Model creation\n",
                "model = VAE(input_dim=x_train.shape[1], latent_dim=32,\n",
                "            encoder=Encoder_MLP, decoder=Decoder_MLP, layers_conf=[64])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Training\n",
                "\n",
                "Define the training pipeline. There you can fix some hyperparameters related to the training phase of the autoencoder, like learning rate, bath size, numer of epochs, etc.\n",
                "Here you can define callbacks to the model.\n",
                "Also the pipeline's name can be customized to facilitate the identification of the corresponding folder with the saved models inside output_dir folder."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-01-11 20:58:41 \u001b[32m[INFO]\u001b[0m: +++ training_pipeline_mnist_mlp_vae +++\u001b[0m\n",
                        "2024-01-11 20:58:41 \u001b[32m[INFO]\u001b[0m: Creating folder in ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41\u001b[0m\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/40\n",
                        "\n",
                        "Epoch 1: loss improved from inf to 0.09324, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 5ms/step - kl_loss: 0.0236 - loss: 0.0932 - reconstruction_loss: 0.0696\n",
                        "Epoch 2/40\n",
                        "\n",
                        "Epoch 2: loss improved from 0.09324 to 0.06775, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 5ms/step - kl_loss: 1.9597e-07 - loss: 0.0677 - reconstruction_loss: 0.0677\n",
                        "Epoch 3/40\n",
                        "\n",
                        "Epoch 3: loss improved from 0.06775 to 0.06761, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 5ms/step - kl_loss: 1.8123e-07 - loss: 0.0676 - reconstruction_loss: 0.0676\n",
                        "Epoch 4/40\n",
                        "\n",
                        "Epoch 4: loss improved from 0.06761 to 0.06757, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 5ms/step - kl_loss: 1.7831e-07 - loss: 0.0676 - reconstruction_loss: 0.0676\n",
                        "Epoch 5/40\n",
                        "\n",
                        "Epoch 5: loss improved from 0.06757 to 0.06751, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 5ms/step - kl_loss: 1.7246e-07 - loss: 0.0675 - reconstruction_loss: 0.0675\n",
                        "Epoch 6/40\n",
                        "\n",
                        "Epoch 6: loss improved from 0.06751 to 0.06744, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 5ms/step - kl_loss: 1.6388e-07 - loss: 0.0674 - reconstruction_loss: 0.0674\n",
                        "Epoch 7/40\n",
                        "\n",
                        "Epoch 7: loss improved from 0.06744 to 0.06740, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 5ms/step - kl_loss: 1.7163e-07 - loss: 0.0674 - reconstruction_loss: 0.0674\n",
                        "Epoch 8/40\n",
                        "\n",
                        "Epoch 8: loss improved from 0.06740 to 0.06737, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 5ms/step - kl_loss: 1.6439e-07 - loss: 0.0674 - reconstruction_loss: 0.0674\n",
                        "Epoch 9/40\n",
                        "\n",
                        "Epoch 9: loss improved from 0.06737 to 0.06736, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 5ms/step - kl_loss: 1.7278e-07 - loss: 0.0674 - reconstruction_loss: 0.0674\n",
                        "Epoch 10/40\n",
                        "\n",
                        "Epoch 10: loss improved from 0.06736 to 0.06733, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 5ms/step - kl_loss: 1.6541e-07 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 11/40\n",
                        "\n",
                        "Epoch 11: loss improved from 0.06733 to 0.06732, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 5ms/step - kl_loss: 1.6744e-07 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 12/40\n",
                        "\n",
                        "Epoch 12: loss improved from 0.06732 to 0.06731, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 5ms/step - kl_loss: 1.7081e-07 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 13/40\n",
                        "\n",
                        "Epoch 13: loss improved from 0.06731 to 0.06731, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 5ms/step - kl_loss: 2.0811e-07 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 14/40\n",
                        "\n",
                        "Epoch 14: loss improved from 0.06731 to 0.06730, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 2.6593e-07 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 15/40\n",
                        "\n",
                        "Epoch 15: loss improved from 0.06730 to 0.06730, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 5ms/step - kl_loss: 3.1289e-07 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 16/40\n",
                        "\n",
                        "Epoch 16: loss improved from 0.06730 to 0.06730, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 5.7126e-07 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 17/40\n",
                        "\n",
                        "Epoch 17: loss did not improve from 0.06730\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 7.4677e-07 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 18/40\n",
                        "\n",
                        "Epoch 18: loss improved from 0.06730 to 0.06729, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.0851e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 19/40\n",
                        "\n",
                        "Epoch 19: loss did not improve from 0.06729\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.4115e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 20/40\n",
                        "\n",
                        "Epoch 20: loss improved from 0.06729 to 0.06729, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.6151e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 21/40\n",
                        "\n",
                        "Epoch 21: loss improved from 0.06729 to 0.06728, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.8418e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 22/40\n",
                        "\n",
                        "Epoch 22: loss improved from 0.06728 to 0.06728, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.7418e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 23/40\n",
                        "\n",
                        "Epoch 23: loss improved from 0.06728 to 0.06728, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.8255e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 24/40\n",
                        "\n",
                        "Epoch 24: loss improved from 0.06728 to 0.06728, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.8290e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 25/40\n",
                        "\n",
                        "Epoch 25: loss improved from 0.06728 to 0.06728, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.8471e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 26/40\n",
                        "\n",
                        "Epoch 26: loss did not improve from 0.06728\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.8165e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 27/40\n",
                        "\n",
                        "Epoch 27: loss did not improve from 0.06728\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.9445e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 28/40\n",
                        "\n",
                        "Epoch 28: loss did not improve from 0.06728\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.7257e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 29/40\n",
                        "\n",
                        "Epoch 29: loss improved from 0.06728 to 0.06727, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.7900e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 30/40\n",
                        "\n",
                        "Epoch 30: loss did not improve from 0.06727\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.7934e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 31/40\n",
                        "\n",
                        "Epoch 31: loss improved from 0.06727 to 0.06727, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.9172e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 32/40\n",
                        "\n",
                        "Epoch 32: loss improved from 0.06727 to 0.06727, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.7746e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 33/40\n",
                        "\n",
                        "Epoch 33: loss did not improve from 0.06727\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.9124e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 34/40\n",
                        "\n",
                        "Epoch 34: loss did not improve from 0.06727\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.8251e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 35/40\n",
                        "\n",
                        "Epoch 35: loss did not improve from 0.06727\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 2.1063e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 36/40\n",
                        "\n",
                        "Epoch 36: loss did not improve from 0.06727\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.5436e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 37/40\n",
                        "\n",
                        "Epoch 37: loss improved from 0.06727 to 0.06727, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.8005e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 38/40\n",
                        "\n",
                        "Epoch 38: loss improved from 0.06727 to 0.06727, saving model to ../output_dir/training_pipeline_mnist_mlp_vae_2024-01-11_20-58-41/model.weights.h5\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.8572e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 39/40\n",
                        "\n",
                        "Epoch 39: loss did not improve from 0.06727\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.8882e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n",
                        "Epoch 40/40\n",
                        "\n",
                        "Epoch 40: loss did not improve from 0.06727\n",
                        "469/469 - 2s - 4ms/step - kl_loss: 1.7370e-06 - loss: 0.0673 - reconstruction_loss: 0.0673\n"
                    ]
                }
            ],
            "source": [
                "pipe = TrainingPipeline(name='training_pipeline_mnist_mlp_vae', learning_rate=0.01,\n",
                "                        model=model, num_epochs=40, batch_size=128)\n",
                "\n",
                "trained_model = pipe(x=x_train, y=x_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 2000x400 with 20 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "outputs = trained_model.predict(x_test)\n",
                "\n",
                "plot_reconstructions(x_test, outputs['recon'])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "keras_core",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
