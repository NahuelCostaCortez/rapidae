{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Recurrent VAE + Regressor with CMAPPS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fist install the library\n",
    "\n",
    "#%pip install aepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Rapidae uses the new version of Keras 3, this allows the use of different backends. \n",
    "We can select among the 3 available backends (Tensorflow, Pytorch and Jax) by modifying the environment variable \"KERAS_BACKEND\".\n",
    "In the next cell we can define it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath('')\n",
    "sys.path.append(os.path.join(notebook_dir, '..'))\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from rapidae.data import utils\n",
    "from rapidae.data.datasets import load_CMAPSS\n",
    "from rapidae.data.preprocessing import CMAPSS_preprocessor\n",
    "from rapidae.data.utils import evaluate\n",
    "from rapidae.metrics import cmapps_score\n",
    "from rapidae.models.base import RecurrentDecoder, RecurrentEncoder\n",
    "from rapidae.models.vae import VAE\n",
    "from rapidae.pipelines import PreprocessPipeline, TrainingPipeline\n",
    "\n",
    "# Reproducibility in Keras. This will set:\n",
    "# 1) `numpy` seed\n",
    "# 2) backend random seed\n",
    "# 3) `python` random seed\n",
    "keras.utils.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix some parameters of the data:\n",
    " - The selected subdataset of CMAPSS\n",
    " - The specific sensors\n",
    " - The length of the window\n",
    " - The smoothing instensity\n",
    " - The max RUL\n",
    "\n",
    "For more information you can check the paper: https://www.sciencedirect.com/science/article/pii/S2665963822000537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'FD003'\n",
    "# sensors to work with: T30, T50, P30, PS30, phi\n",
    "sensors = ['s_3', 's_4', 's_7', 's_11', 's_12']\n",
    "# windows length\n",
    "sequence_length = 30\n",
    "# smoothing intensity\n",
    "alpha = 0.1\n",
    "# max RUL\n",
    "threshold = 125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and preprocess the dataset\n",
    "\n",
    "Download the dataset and create a pipeline for preprocessing. CMAPSS datassets consists of multiple multivariate time series. Each data set is further divided into training and test subsets. Each time series is from a different engine i.e., the data can be considered to be from a fleet of engines of the same type \n",
    "\n",
    "The CMAPSS_preprocessor encapsulates a set of operations in order to prepare properly the data, like generating the RUL values, remove unused sensors, scaling, smoothing, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 11:28:00 \u001b[32m[INFO]\u001b[0m: +++ CMAPPS_preprocessing +++\u001b[0m\n",
      "2023-12-26 11:28:00 \u001b[32m[INFO]\u001b[0m: Creating folder in ../output_dir/CMAPPS_preprocessing_2023-12-26_11-28-00\u001b[0m\n",
      "2023-12-26 11:28:00 \u001b[32m[INFO]\u001b[0m: Selected preprocessor is a function.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# NOT IMPLEMENTED YET\n",
    "# x_train, y_train, x_val, y_val, x_test, y_test = utils.get_data(dataset, sensors,\n",
    "# sequence_length, alpha, threshold)\n",
    "\n",
    "train, test, y_test = load_CMAPSS(dataset)\n",
    "\n",
    "preprocess_pipeline = PreprocessPipeline(\n",
    "    name='CMAPPS_preprocessing', preprocessor=CMAPSS_preprocessor)\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = preprocess_pipeline(\n",
    "    train=train, test=test, y_test=y_test, threshold=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation\n",
    "\n",
    "Fix hyperparameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = x_train.shape[1]\n",
    "input_dim = x_train.shape[2]\n",
    "intermediate_dim = 300\n",
    "batch_size = 128\n",
    "latent_dim = 2\n",
    "epochs = 2\n",
    "optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the VAE model. Since in this example we are working with time series, the encoder and the decoder are recurren LSTM layers.\n",
    "Also a classifier is also added taking as input the latent space of the autoencoder. This regressor will be in charge of trying to predict the RUL value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 11:28:00 \u001b[33m[WARNING]\u001b[0m: No specific layer configuration has been provided. Creating default configuration...\u001b[0m\n",
      "2023-12-26 11:28:00.679992: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-26 11:28:00.680025: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-26 11:28:00.680865: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-26 11:28:00.686089: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-26 11:28:01.382692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-26 11:28:01 \u001b[32m[INFO]\u001b[0m: Regressor available for the latent space of the autoencoder\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = VAE(input_dim=(x_train.shape[1], x_train.shape[2]), latent_dim=2, \n",
    "            downstream_task='regression', encoder=RecurrentEncoder, decoder=RecurrentDecoder)\n",
    "# model_callbacks = utils.get_callbacks(\"p\", model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training pipeline \n",
    "\n",
    "Create and lauch the pipeline to train the model, in this example we have evaluation data so it can be passed as a dict to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 11:42:22 \u001b[32m[INFO]\u001b[0m: +++ TrainingPipeline +++\u001b[0m\n",
      "2023-12-26 11:42:22 \u001b[32m[INFO]\u001b[0m: Creating folder in ../output_dir/TrainingPipeline_2023-12-26_11-42-22\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 2604.14917, saving model to ../output_dir/TrainingPipeline_2023-12-26_11-42-22/model.weights.h5\n",
      "139/139 - 18s - 127ms/step - kl_loss: 134.6815 - loss: 4440.4424 - reconstruction_loss: 0.4656 - reg_loss: 4305.2935 - val_kl_loss: 136.0072 - val_loss: 2604.1492 - val_reconstruction_loss: 0.5051 - val_reg_loss: 2467.6367\n"
     ]
    }
   ],
   "source": [
    "pipeline = TrainingPipeline(model=model, num_epochs=1)\n",
    "trained_model = pipeline(x=x_train, y=y_train, x_eval=x_val, y_eval=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation step\n",
    "\n",
    "Let's now make evaluate the model over the test set. The selected metrics to evaluate this are the mean square error and the CMAPSS score.\n",
    "Here we can see the difference between using the evaluate method with a metric imported from the Scikit-Learn library and a custom one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "test set results: [\n",
      "\t mean_squared_error: 3162.858564886078 \n",
      "]\n",
      "test set results: [\n",
      "\t CMAPSS_Score: 396007.9105769672 \n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(396007.91057697)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = trained_model.predict(x_test)\n",
    "\n",
    "evaluate(y_true=np.expand_dims(y_test, axis=-1),\n",
    "         y_hat=y_hat['reg'], sel_metric=mean_squared_error)\n",
    "evaluate(y_true=np.expand_dims(y_test, axis=-1),\n",
    "         y_hat=y_hat['reg'], sel_metric=cmapps_score.CMAPSS_Score())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aepy-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
