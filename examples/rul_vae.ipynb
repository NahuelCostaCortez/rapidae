{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Recurrent VAE + Regressor with CMAPPS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First install the library\n",
    "\n",
    "# %pip install aepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Rapidae uses the new version of Keras 3, this allows the use of different backends. \n",
    "We can select among the 3 available backends (Tensorflow, Pytorch and Jax) by modifying the environment variable \"KERAS_BACKEND\".\n",
    "In the next cell we can define it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-31 20:33:28.108124: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-31 20:33:28.108154: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-31 20:33:28.108858: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-31 20:33:28.114508: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-31 20:33:28.710698: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "#notebook_dir = os.path.abspath('')\n",
    "#sys.path.append(os.path.join(notebook_dir, '..', 'src'))\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from rapidae.pipelines import PreprocessPipeline, TrainingPipeline\n",
    "from rapidae.models.vae import VAE\n",
    "from rapidae.models.base import RecurrentDecoder, RecurrentEncoder\n",
    "from rapidae.metrics import cmapps_score\n",
    "from rapidae.data.utils import evaluate\n",
    "from rapidae.data.preprocessing import CMAPSS_preprocessor\n",
    "from rapidae.data.datasets import load_CMAPSS\n",
    "\n",
    "\n",
    "# For reproducibility in Keras 3. This will set:\n",
    "# 1) `numpy` seed\n",
    "# 2) backend random seed\n",
    "# 3) `python` random seed\n",
    "keras.utils.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix some parameters of the data:\n",
    " - The selected subdataset of CMAPSS\n",
    " - The specific sensors\n",
    " - The length of the window\n",
    " - The smoothing instensity\n",
    " - The max RUL\n",
    "\n",
    "For more information you can check the paper: https://www.sciencedirect.com/science/article/pii/S2665963822000537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'FD003'\n",
    "# sensors to work with: T30, T50, P30, PS30, phi\n",
    "sensors = ['s_3', 's_4', 's_7', 's_11', 's_12']\n",
    "# windows length\n",
    "sequence_length = 30\n",
    "# smoothing intensity\n",
    "alpha = 0.1\n",
    "# max RUL\n",
    "threshold = 125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and preprocess the dataset\n",
    "\n",
    "Download the dataset and create a pipeline for preprocessing. CMAPSS datassets consists of multiple multivariate time series. Each data set is further divided into training and test subsets. Each time series is from a different engine i.e., the data can be considered to be from a fleet of engines of the same type \n",
    "\n",
    "The CMAPSS_preprocessor encapsulates a set of operations in order to prepare properly the data, like generating the RUL values, remove unused sensors, scaling, smoothing, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-31 20:33:30 \u001b[32m[INFO]\u001b[0m: +++ CMAPPS_preprocessing +++\u001b[0m\n",
      "2023-12-31 20:33:30 \u001b[32m[INFO]\u001b[0m: Creating folder in ../output_dir/CMAPPS_preprocessing_2023-12-31_20-33-30\u001b[0m\n",
      "2023-12-31 20:33:30 \u001b[32m[INFO]\u001b[0m: Selected preprocessor is a function.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# NOT IMPLEMENTED YET\n",
    "# x_train, y_train, x_val, y_val, x_test, y_test = utils.get_data(dataset, sensors,\n",
    "# sequence_length, alpha, threshold)\n",
    "\n",
    "train, test, y_test = load_CMAPSS(dataset)\n",
    "\n",
    "preprocess_pipeline = PreprocessPipeline(\n",
    "    name='CMAPPS_preprocessing', preprocessor=CMAPSS_preprocessor)\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = preprocess_pipeline(\n",
    "    train=train, test=test, y_test=y_test, threshold=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation\n",
    "\n",
    "Fix hyperparameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = x_train.shape[1]\n",
    "input_dim = x_train.shape[2]\n",
    "intermediate_dim = 300\n",
    "batch_size = 128\n",
    "latent_dim = 2\n",
    "epochs = 2\n",
    "optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the VAE model. Since in this example we are working with time series, the encoder and the decoder are recurren LSTM layers.\n",
    "Also a classifier is also added taking as input the latent space of the autoencoder. This regressor will be in charge of trying to predict the RUL value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-31 20:34:36 \u001b[33m[WARNING]\u001b[0m: No specific layer configuration has been provided. Creating default configuration...\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'masking_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mVAE\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownstream_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mregression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRecurrentEncoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRecurrentDecoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# model_callbacks = utils.get_callbacks(\"p\", model, x_train, y_train)\u001b[39;00m\n",
      "File \u001b[0;32m~/aepy-project/rapidae/examples/../src/rapidae/models/vae/vae_model.py:30\u001b[0m, in \u001b[0;36mVAE.__init__\u001b[0;34m(self, input_dim, latent_dim, exclude_decoder, downstream_task, encoder, decoder, layers_conf, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     21\u001b[0m     input_dim: Union[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     29\u001b[0m ):\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mBaseAE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers_conf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayers_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownstream_task \u001b[38;5;241m=\u001b[39m downstream_task\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude_decoder \u001b[38;5;241m=\u001b[39m exclude_decoder\n",
      "File \u001b[0;32m~/aepy-project/rapidae/examples/../src/rapidae/models/base/base_model.py:62\u001b[0m, in \u001b[0;36mBaseAE.__init__\u001b[0;34m(self, input_dim, latent_dim, encoder, decoder, uses_default_encoder, uses_default_decoder, layers_conf, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo input dimension provided!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_dim\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be provided in the model config\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m         )\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m Encoder_MLP(\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_conf)\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers_conf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     Logger()\u001b[38;5;241m.\u001b[39mlog_warning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo decoder provider, using default MLP decoder\u001b[39m\u001b[38;5;124m'\u001b[39m),\n",
      "File \u001b[0;32m~/aepy-project/rapidae/examples/../src/rapidae/models/base/default_architectures.py:228\u001b[0m, in \u001b[0;36mRecurrentEncoder.__init__\u001b[0;34m(self, input_dim, latent_dim, layers_conf, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m BaseEncoder\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dim, latent_dim, layers_conf)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasking_value \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasking_value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmasking_value\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m99.0\u001b[39m\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mMasking(mask_value\u001b[38;5;241m=\u001b[39m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmasking_value\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mBidirectional(layers\u001b[38;5;241m.\u001b[39mLSTM(\u001b[38;5;241m300\u001b[39m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'masking_value'"
     ]
    }
   ],
   "source": [
    "model = VAE(input_dim=(x_train.shape[1], x_train.shape[2]), latent_dim=2,\n",
    "            downstream_task='regression', encoder=RecurrentEncoder, decoder=RecurrentDecoder)\n",
    "# model_callbacks = utils.get_callbacks(\"p\", model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training pipeline \n",
    "\n",
    "Create and lauch the pipeline to train the model, in this example we have evaluation data so it can be passed as a dict to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = TrainingPipeline(\n",
    "    name='training_pipeline_rul_vae', model=model, num_epochs=1)\n",
    "trained_model = pipeline(x=x_train, y=y_train, x_eval=x_val, y_eval=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation step\n",
    "\n",
    "Let's now make evaluate the model over the test set. The selected metrics to evaluate this are the mean square error and the CMAPSS score.\n",
    "Here we can see the difference between using the evaluate method with a metric imported from the Scikit-Learn library and a custom one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = trained_model.predict(x_test)\n",
    "\n",
    "evaluate(y_true=np.expand_dims(y_test, axis=-1),\n",
    "         y_hat=y_hat['reg'], sel_metric=mean_squared_error)\n",
    "evaluate(y_true=np.expand_dims(y_test, axis=-1),\n",
    "         y_hat=y_hat['reg'], sel_metric=cmapps_score.CMAPSS_Score())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aepy-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
