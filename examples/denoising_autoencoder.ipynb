{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Denoising Autoencoder with MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First install the library\n",
    "\n",
    "#%pip install rapidae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Rapidae uses the new version of Keras 3, this allows the use of different backends. \n",
    "We can select among the 3 available backends (Tensorflow, Pytorch and Jax) by modifying the environment variable \"KERAS_BACKEND\".\n",
    "In the next cell we can define it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from rapidae.data.datasets import load_MNIST\n",
    "from rapidae.data.utils import display_diff, add_noise\n",
    "from rapidae.models.ae.ae_model import AE\n",
    "from rapidae.models.base.default_architectures import VanillaEncoder, VanillaDecoder\n",
    "from rapidae.pipelines.training import TrainingPipeline\n",
    "\n",
    "# Reproducibility in Keras. This will set:\n",
    "# 1) `numpy` seed\n",
    "# 2) backend random seed\n",
    "# 3) `python` random seed\n",
    "keras.utils.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and preprocess the dataset\n",
    "\n",
    "Download and preprocess the dataset. In this example, the selected dataset is the well-known MNIST composed of handwritten number images.\n",
    "\n",
    "The \"persistant\" parameter of the load_MNIST() serves as a flag to determine if we want the dataset to be cached in the datasets folder.\n",
    "\n",
    "Train and test data are normalized and flatten since we are going to use a non convolutional autoencoder.\n",
    "\n",
    "Since we want to train a denoising autoencoder, we also need to add some noise to the images.\n",
    "The noise factor should be a float between 0 and 1 depending the intensity of the noise.\n",
    "\n",
    "The used autoencoder to denoise the images is vanilla without convolutional layers so we need to flatten the images before we use it as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 13:54:19 \u001b[32m[INFO]\u001b[0m: train-images-idx3-ubyte.gz already exists.\u001b[0m\n",
      "2023-12-28 13:54:19 \u001b[32m[INFO]\u001b[0m: train-labels-idx1-ubyte.gz already exists.\u001b[0m\n",
      "2023-12-28 13:54:19 \u001b[32m[INFO]\u001b[0m: t10k-images-idx3-ubyte.gz already exists.\u001b[0m\n",
      "2023-12-28 13:54:19 \u001b[32m[INFO]\u001b[0m: t10k-labels-idx1-ubyte.gz already exists.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "x_train, y_train, x_test, y_test = load_MNIST(persistant=True)\n",
    "\n",
    "# Add noise to the train and test data\n",
    "x_train_noisy = add_noise(x_train, noise_factor=0.4)\n",
    "x_test_noisy = add_noise(x_test, noise_factor=0.4)\n",
    "\n",
    "# Flatten data\n",
    "x_train = x_train.reshape(x_train.shape[0], -1).astype('float32') / 255\n",
    "x_train_noisy = x_train_noisy.reshape(x_train_noisy.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1).astype('float32') / 255\n",
    "x_test_noisy = x_test_noisy.reshape(x_test_noisy.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation\n",
    "\n",
    "Since the denoising autoencoder in structure is a vanilla autoencoder (only its functionality varies), the encoder and decoder are the vanilla ones, depth of the network and number of neurons per layer can be defined by using the layers_conf parameter.\n",
    "The latent_dim determinates the dimensionality of the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation\n",
    "model = AE(input_dim=x_train_noisy.shape[1], latent_dim=10,\n",
    "           encoder=VanillaEncoder, decoder=VanillaDecoder, layers_conf=[64, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training pipeline\n",
    "\n",
    "Define the training pipeline. There you can fix some hyperparameters related to the training phase of the autoencoder, like learning rate, bath size, numer of epochs, etc.\n",
    "Here you can define callbacks to the model.\n",
    "Also the pipeline's name can be customized to facilitate the identification of the corresponding folder with the saved models inside output_dir folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 13:54:20 \u001b[32m[INFO]\u001b[0m: +++ training_pipeline +++\u001b[0m\n",
      "2023-12-28 13:54:20 \u001b[32m[INFO]\u001b[0m: Creating folder in ../output_dir/training_pipeline_2023-12-28_13-54-20\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.10381, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.1038\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 2: loss improved from 0.10381 to 0.08684, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0868\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 3: loss improved from 0.08684 to 0.08267, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0827\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 4: loss improved from 0.08267 to 0.08101, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0810\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 5: loss improved from 0.08101 to 0.07998, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0800\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 6: loss improved from 0.07998 to 0.07902, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0790\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 7: loss improved from 0.07902 to 0.07757, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0776\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 8: loss improved from 0.07757 to 0.07674, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0767\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 9: loss improved from 0.07674 to 0.07622, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0762\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 10: loss improved from 0.07622 to 0.07580, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0758\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 11: loss improved from 0.07580 to 0.07542, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0754\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 12: loss improved from 0.07542 to 0.07509, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0751\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 13: loss improved from 0.07509 to 0.07478, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0748\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 14: loss improved from 0.07478 to 0.07450, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0745\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 15: loss improved from 0.07450 to 0.07424, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0742\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 16: loss improved from 0.07424 to 0.07400, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0740\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 17: loss improved from 0.07400 to 0.07381, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0738\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 18: loss improved from 0.07381 to 0.07364, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0736\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 19: loss improved from 0.07364 to 0.07351, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0735\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 20: loss improved from 0.07351 to 0.07338, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0734\n",
      "Epoch 21/50\n",
      "\n",
      "Epoch 21: loss improved from 0.07338 to 0.07329, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0733\n",
      "Epoch 22/50\n",
      "\n",
      "Epoch 22: loss improved from 0.07329 to 0.07317, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0732\n",
      "Epoch 23/50\n",
      "\n",
      "Epoch 23: loss improved from 0.07317 to 0.07305, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0731\n",
      "Epoch 24/50\n",
      "\n",
      "Epoch 24: loss improved from 0.07305 to 0.07296, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0730\n",
      "Epoch 25/50\n",
      "\n",
      "Epoch 25: loss improved from 0.07296 to 0.07289, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0729\n",
      "Epoch 26/50\n",
      "\n",
      "Epoch 26: loss improved from 0.07289 to 0.07281, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0728\n",
      "Epoch 27/50\n",
      "\n",
      "Epoch 27: loss improved from 0.07281 to 0.07274, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0727\n",
      "Epoch 28/50\n",
      "\n",
      "Epoch 28: loss improved from 0.07274 to 0.07267, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0727\n",
      "Epoch 29/50\n",
      "\n",
      "Epoch 29: loss improved from 0.07267 to 0.07262, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0726\n",
      "Epoch 30/50\n",
      "\n",
      "Epoch 30: loss improved from 0.07262 to 0.07254, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0725\n",
      "Epoch 31/50\n",
      "\n",
      "Epoch 31: loss improved from 0.07254 to 0.07252, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0725\n",
      "Epoch 32/50\n",
      "\n",
      "Epoch 32: loss improved from 0.07252 to 0.07244, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0724\n",
      "Epoch 33/50\n",
      "\n",
      "Epoch 33: loss improved from 0.07244 to 0.07240, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0724\n",
      "Epoch 34/50\n",
      "\n",
      "Epoch 34: loss improved from 0.07240 to 0.07233, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0723\n",
      "Epoch 35/50\n",
      "\n",
      "Epoch 35: loss improved from 0.07233 to 0.07227, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0723\n",
      "Epoch 36/50\n",
      "\n",
      "Epoch 36: loss improved from 0.07227 to 0.07224, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0722\n",
      "Epoch 37/50\n",
      "\n",
      "Epoch 37: loss improved from 0.07224 to 0.07219, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0722\n",
      "Epoch 38/50\n",
      "\n",
      "Epoch 38: loss improved from 0.07219 to 0.07215, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0721\n",
      "Epoch 39/50\n",
      "\n",
      "Epoch 39: loss improved from 0.07215 to 0.07211, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0721\n",
      "Epoch 40/50\n",
      "\n",
      "Epoch 40: loss improved from 0.07211 to 0.07207, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0721\n",
      "Epoch 41/50\n",
      "\n",
      "Epoch 41: loss improved from 0.07207 to 0.07203, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0720\n",
      "Epoch 42/50\n",
      "\n",
      "Epoch 42: loss improved from 0.07203 to 0.07198, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0720\n",
      "Epoch 43/50\n",
      "\n",
      "Epoch 43: loss improved from 0.07198 to 0.07196, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0720\n",
      "Epoch 44/50\n",
      "\n",
      "Epoch 44: loss improved from 0.07196 to 0.07192, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0719\n",
      "Epoch 45/50\n",
      "\n",
      "Epoch 45: loss improved from 0.07192 to 0.07188, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0719\n",
      "Epoch 46/50\n",
      "\n",
      "Epoch 46: loss improved from 0.07188 to 0.07185, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0718\n",
      "Epoch 47/50\n",
      "\n",
      "Epoch 47: loss improved from 0.07185 to 0.07182, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0718\n",
      "Epoch 48/50\n",
      "\n",
      "Epoch 48: loss improved from 0.07182 to 0.07179, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0718\n",
      "Epoch 49/50\n",
      "\n",
      "Epoch 49: loss improved from 0.07179 to 0.07177, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 3ms/step - loss: 0.0718\n",
      "Epoch 50/50\n",
      "\n",
      "Epoch 50: loss improved from 0.07177 to 0.07174, saving model to ../output_dir/training_pipeline_2023-12-28_13-54-20/model.weights.h5\n",
      "469/469 - 2s - 4ms/step - loss: 0.0717\n"
     ]
    }
   ],
   "source": [
    "pipe = TrainingPipeline(name='training_pipeline',\n",
    "                        model=model, num_epochs=50)\n",
    "\n",
    "trained_model = pipe(x=x_train_noisy, y=x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation step \n",
    "\n",
    "Finally the original images with noise can be graphically compared with the output images of the autoencoder.\n",
    "As you can see, the added noise of the input images has largely disappeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_hat = trained_model.predict(x_test_noisy)\n",
    "display_diff(x_test_noisy, y_hat['recon'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aepy-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
