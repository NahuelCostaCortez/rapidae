{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fist install the library\n",
    "\n",
    "#%pip install aepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath('')\n",
    "sys.path.append(os.path.join(notebook_dir, '..'))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras import utils\n",
    "\n",
    "from rapidae.data.datasets import load_MNIST\n",
    "from rapidae.data.utils import evaluate, display_diff, add_noise\n",
    "from rapidae.models.ae.ae_model import AE\n",
    "from rapidae.models.base.default_architectures import VanillaEncoder, VanillaDecoder\n",
    "from rapidae.pipelines.training import TrainingPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and preprocess the dataset. In this example, the selected dataset is the well-known MNIST composed of handwritten number images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 19:26:02 \u001b[32m[INFO]\u001b[0m: train-images-idx3-ubyte.gz already exists.\u001b[0m\n",
      "2023-12-20 19:26:02 \u001b[32m[INFO]\u001b[0m: train-labels-idx1-ubyte.gz already exists.\u001b[0m\n",
      "2023-12-20 19:26:02 \u001b[32m[INFO]\u001b[0m: t10k-images-idx3-ubyte.gz already exists.\u001b[0m\n",
      "2023-12-20 19:26:02 \u001b[32m[INFO]\u001b[0m: t10k-labels-idx1-ubyte.gz already exists.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "x_train, y_train, x_test, y_test = load_MNIST(persistant=True)\n",
    "\n",
    "# Obtaint number of clasess\n",
    "n_classes = len(set(y_train))\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train = utils.to_categorical(y_train, n_classes)\n",
    "y_test = utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to train a denoising autoencoder, we also need to add some noise to the images.\n",
    "The noise factor should be a float between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to the train and test data\n",
    "x_train_noisy = add_noise(x_train, noise_factor=0.4)\n",
    "x_test_noisy = add_noise(x_test, noise_factor=0.4)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_train_noisy = x_train_noisy.reshape(x_train_noisy.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "x_test_noisy = x_test_noisy.reshape(x_test_noisy.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose the dictionaries to feed the autoencoder during training and evaluation phase.\n",
    "Note in train how the train labels correspond to the original MNIST images (without noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dict(data=x_train_noisy.astype(float), labels=x_train)\n",
    "test_data = dict(data=x_test_noisy.astype(float), labels=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the denoising autoencoder in structure is a normal autoencoder (only its functionality varies), the encoder and decoder are the vanilla ones, you can specify the depth and number of neurons per layer in each using the layers_conf parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation\n",
    "model = AE(input_dim=x_train_noisy.shape[1], latent_dim=2,\n",
    "           encoder=VanillaEncoder, decoder=VanillaDecoder, layers_conf=[64, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training pipeline. There you can fix some hyperparameters realted to the training phase of the autoencoder, like learning rate, bath size, numer of epochs, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 19:26:03 \u001b[32m[INFO]\u001b[0m: +++ training_pipeline +++\u001b[0m\n",
      "2023-12-20 19:26:03 \u001b[32m[INFO]\u001b[0m: Creating folder in ../output_dir/training_pipeline_2023-12-20_19-26-03\u001b[0m\n",
      "2023-12-20 19:26:03.830569: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-20 19:26:03.915676: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-20 19:26:03.915864: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-20 19:26:03.917563: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-20 19:26:03.917722: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-20 19:26:03.917849: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-20 19:26:03.974084: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-20 19:26:03.974251: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-20 19:26:03.974389: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-20 19:26:03.974487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5722 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:27:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucaspc/venvs/keras_core/lib/python3.11/site-packages/keras/src/layers/layer.py:1217: UserWarning: Layer 'encoder' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encoutered: ''Layer 'dense_6' expected 1 input(s). Received 2 instead.''\n",
      "  warnings.warn(\n",
      "/home/lucaspc/venvs/keras_core/lib/python3.11/site-packages/keras/src/layers/layer.py:358: UserWarning: `build()` was called on layer 'encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/home/lucaspc/venvs/keras_core/lib/python3.11/site-packages/keras/src/layers/layer.py:1217: UserWarning: Layer 'ae_1' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encoutered: ''Exception encountered when calling VanillaEncoder.call().\n",
      "\n",
      "\u001b[1mLayer 'dense_6' expected 1 input(s). Received 2 instead.\u001b[0m\n",
      "\n",
      "Arguments received by VanillaEncoder.call():\n",
      "  • x={'data': 'tf.Tensor(shape=(128, 784), dtype=float32)', 'labels': 'tf.Tensor(shape=(128, 784), dtype=uint8)'}''\n",
      "  warnings.warn(\n",
      "/home/lucaspc/venvs/keras_core/lib/python3.11/site-packages/keras/src/layers/layer.py:358: UserWarning: `build()` was called on layer 'ae_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling VanillaEncoder.call().\n\n\u001b[1mLayer 'dense_6' expected 1 input(s). Received 2 instead.\u001b[0m\n\nArguments received by VanillaEncoder.call():\n  • x={'data': 'tf.Tensor(shape=(128, 784), dtype=float32)', 'labels': 'tf.Tensor(shape=(128, 784), dtype=uint8)'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/lucaspc/aepy-project/aepy/examples/denoising_autoencoder.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucaspc/aepy-project/aepy/examples/denoising_autoencoder.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pipe \u001b[39m=\u001b[39m TrainingPipeline(name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtraining_pipeline\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucaspc/aepy-project/aepy/examples/denoising_autoencoder.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                         model\u001b[39m=\u001b[39mmodel, num_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/lucaspc/aepy-project/aepy/examples/denoising_autoencoder.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m trained_model \u001b[39m=\u001b[39m pipe(train_data)\n",
      "File \u001b[0;32m~/aepy-project/aepy/examples/../rapidae/pipelines/training.py:94\u001b[0m, in \u001b[0;36mTrainingPipeline.__call__\u001b[0;34m(self, x, y, x_eval, y_eval, callbacks, save_model)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer, run_eagerly\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m x_eval \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     95\u001b[0m                 x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m     96\u001b[0m                 y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m     97\u001b[0m                 shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     98\u001b[0m                 epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_epochs,\n\u001b[1;32m     99\u001b[0m                 batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[1;32m    100\u001b[0m                 callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    101\u001b[0m                 verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    102\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(\n\u001b[1;32m    104\u001b[0m                 x\u001b[39m=\u001b[39mx,\n\u001b[1;32m    105\u001b[0m                 y\u001b[39m=\u001b[39my,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m    111\u001b[0m                 verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/venvs/keras_core/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[39m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/aepy-project/aepy/examples/../rapidae/models/ae/ae_model.py:37\u001b[0m, in \u001b[0;36mAE.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 37\u001b[0m     z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[1;32m     38\u001b[0m     recon_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(z)\n\u001b[1;32m     39\u001b[0m     outputs \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/aepy-project/aepy/examples/../rapidae/models/base/default_architectures.py:387\u001b[0m, in \u001b[0;36mVanillaEncoder.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    386\u001b[0m     \u001b[39mfor\u001b[39;00m name, layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers_dict\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 387\u001b[0m         x \u001b[39m=\u001b[39m layer(x)\n\u001b[1;32m    388\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menc_layer(x)\n\u001b[1;32m    389\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling VanillaEncoder.call().\n\n\u001b[1mLayer 'dense_6' expected 1 input(s). Received 2 instead.\u001b[0m\n\nArguments received by VanillaEncoder.call():\n  • x={'data': 'tf.Tensor(shape=(128, 784), dtype=float32)', 'labels': 'tf.Tensor(shape=(128, 784), dtype=uint8)'}"
     ]
    }
   ],
   "source": [
    "pipe = TrainingPipeline(name='training_pipeline',\n",
    "                        model=model, num_epochs=10)\n",
    "\n",
    "trained_model = pipe(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation phase using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = trained_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the original images with noise can be graphically compared with the output images of the autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_diff(x_test_noisy, y_hat['recon'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aepy-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
